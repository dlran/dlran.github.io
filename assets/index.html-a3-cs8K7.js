import{_ as a,c as i,a as s,o as n}from"./app-jG34hMY9.js";const l={};function r(o,e){return n(),i("div",null,e[0]||(e[0]=[s(`<blockquote><p>Anthropic 正式发布 Stable Diffusion 3.5，这是它们迄今为止最强的模型，此公开版本包含多个型号变体，包括 Stable Diffusion 3.5 Large 和 Stable Diffusion 3.5 Large Turbo。此外，Stable Diffusion 3.5 Medium 将于 10 月 29 日发布。<br> 这些模型的尺寸可高度定制，可在消费级硬件上运行，并且根据宽松的Stability AI 社区许可，可免费用于商业和非商业用途。</p></blockquote><hr><h2 id="一、前置准备" tabindex="-1"><a class="header-anchor" href="#一、前置准备"><span>一、前置准备</span></a></h2><p>本教程适用于对 AI 绘图有一定兴趣，想在本地部署 Stable Diffusion 模型的用户。部署目标是：</p><ul><li>使用 <a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" rel="noopener noreferrer">ComfyUI</a> 作为可视化工作流界面；</li><li>使用 Stable Diffusion 3.5 Large Turbo 模型；</li><li>实现完整的文本到图像生成过程。</li></ul><hr><h2 id="二、下载安装-comfyui" tabindex="-1"><a class="header-anchor" href="#二、下载安装-comfyui"><span>二、下载安装 ComfyUI</span></a></h2><p>首先，需要下载 ComfyUI 的 Windows 便携版：</p><ol><li>访问 ComfyUI 官方 GitHub 发布页：<a href="https://github.com/comfyanonymous/ComfyUI/releases" target="_blank" rel="noopener noreferrer">https://github.com/comfyanonymous/ComfyUI/releases</a></li><li>下载最新版本的 <code>ComfyUI_windows_portable</code> 压缩包；</li><li>解压至本地任意目录（建议路径中不要有中文或空格）；</li><li>解压完成后目录结构大致如下：</li></ol><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>ComfyUI/</span></span>
<span class="line"><span>├── run_cpu.bat</span></span>
<span class="line"><span>├── run_nvidia_gpu.bat</span></span>
<span class="line"><span>├── models/</span></span>
<span class="line"><span>│   ├── checkpoint/</span></span>
<span class="line"><span>│   ├── clip/</span></span>
<span class="line"><span>│   └── ...</span></span>
<span class="line"><span>└── ...</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h2 id="三、下载-stable-diffusion-3-5-模型" tabindex="-1"><a class="header-anchor" href="#三、下载-stable-diffusion-3-5-模型"><span>三、下载 Stable Diffusion 3.5 模型</span></a></h2><p>Stable Diffusion 3.5 Large Turbo 是由 StabilityAI 发布的最新轻量版文生图模型：</p><ol><li>登录 <a href="https://huggingface.co" target="_blank" rel="noopener noreferrer">Hugging Face</a> 网站（如没有账号请先注册）；</li><li>前往模型下载页面：<a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/blob/main/sd3.5_large_turbo.safetensors" target="_blank" rel="noopener noreferrer">sd3.5_large_turbo.safetensors</a>；</li><li>下载该模型文件，并放置到 ComfyUI 的以下目录：</li></ol><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>ComfyUI/models/checkpoint/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><hr><h2 id="四、下载所需的-clip-编码模型" tabindex="-1"><a class="header-anchor" href="#四、下载所需的-clip-编码模型"><span>四、下载所需的 CLIP 编码模型</span></a></h2><p>Stable Diffusion 3.5 使用了多个文本编码器（CLIP 和 T5），这些模型文件也需要从 Hugging Face 下载：</p><h3 id="下载以下三个模型" tabindex="-1"><a class="header-anchor" href="#下载以下三个模型"><span>下载以下三个模型：</span></a></h3><ul><li><code>text_encoders/clip_l.safetensors</code></li><li><code>text_encoders/clip_g.safetensors</code></li><li><code>text_encoders/t5xxl_fp8_e4m3fn.safetensors</code></li></ul><blockquote><p>如果你使用的是高端显卡（如 24GB 显存），可以尝试下载更精度的 <code>t5xxl_fp16.safetensors</code> 替换 <code>fp8</code> 版本。</p></blockquote><h3 id="放置路径" tabindex="-1"><a class="header-anchor" href="#放置路径"><span>放置路径：</span></a></h3><p>下载后的文件应放置在以下目录：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>ComfyUI/models/clip/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><hr><h2 id="五、加载官方示例工作流" tabindex="-1"><a class="header-anchor" href="#五、加载官方示例工作流"><span>五、加载官方示例工作流</span></a></h2><p>为了更方便地体验 Stable Diffusion 3.5 的工作流程，Hugging Face 项目还提供了一个官方工作流 JSON 文件。</p><h3 id="操作步骤" tabindex="-1"><a class="header-anchor" href="#操作步骤"><span>操作步骤：</span></a></h3><ol><li><p>下载该示例文件： <a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/blob/main/SD3.5M_example_workflow.json" target="_blank" rel="noopener noreferrer">SD3.5M_example_workflow.json</a></p></li><li><p>启动 ComfyUI 的本地服务：</p><ul><li>如果使用的是 CPU，运行 <code>run_cpu.bat</code></li><li>如果是 Nvidia 显卡用户，运行 <code>run_nvidia_gpu.bat</code>（推荐）</li></ul></li><li><p>浏览器打开 ComfyUI 前端界面，一般为： <a href="http://127.0.0.1:8188" target="_blank" rel="noopener noreferrer">http://127.0.0.1:8188</a></p></li><li><p>将 <code>SD3.5M_example_workflow.json</code> 文件 <strong>直接拖拽</strong> 到 ComfyUI 的前端界面中，加载工作流。</p></li></ol><hr><h2 id="六、配置-triple-clip-loader-节点" tabindex="-1"><a class="header-anchor" href="#六、配置-triple-clip-loader-节点"><span>六、配置 Triple CLIP Loader 节点</span></a></h2><p>示例工作流加载完成后，需要手动在界面中设置 <code>TripleCLIPLoader</code> 节点，指定你下载的 CLIP 模型路径。</p><h3 id="设置方法" tabindex="-1"><a class="header-anchor" href="#设置方法"><span>设置方法：</span></a></h3><ol><li><p>找到图中的 <code>TripleCLIPLoader</code> 节点；</p></li><li><p>在其属性设置中，依次选择：</p><ul><li><code>clip_l.safetensors</code></li><li><code>clip_g.safetensors</code></li><li><code>t5xxl_fp8_e4m3fn.safetensors</code>（或 <code>fp16</code>）</li></ul></li></ol><p>确保这三个模型都正确加载，后续的图像生成就能正常进行。</p><hr><h2 id="七、开始生成图像" tabindex="-1"><a class="header-anchor" href="#七、开始生成图像"><span>七、开始生成图像</span></a></h2><p>至此，你已经完成了所有部署与配置工作！</p><p>在 ComfyUI 中，你可以：</p><ul><li>自由修改 Prompt（提示词）；</li><li>点击右上角运行按钮开始生成；</li><li>生成图像会在右侧展示结果，并可下载。</li></ul><hr><h2 id="八、建议与补充" tabindex="-1"><a class="header-anchor" href="#八、建议与补充"><span>八、建议与补充</span></a></h2><ul><li><strong>显存需求</strong>：建议至少 8GB 显存，若使用 T5 FP16 模型则需更高；</li><li><strong>运行失败？</strong> 可查看命令行窗口输出的错误日志，常见问题包括显存不足或模型路径错误；</li><li><strong>改进体验</strong>：可以尝试使用 <a href="https://github.com/ltdrdata/ComfyUI-Manager" target="_blank" rel="noopener noreferrer">ComfyUI Manager 插件</a> 来快速安装更多节点和模型。</li></ul>`,43)]))}const d=a(l,[["render",r]]),p=JSON.parse('{"path":"/article/fZhPHPy2/","title":"本地部署 Stable Diffusion 3.5 + ComfyUI 实现文生图","lang":"zh-CN","frontmatter":{"title":"本地部署 Stable Diffusion 3.5 + ComfyUI 实现文生图","tags":["AI"],"createTime":"2025/03/02 14:15:27","permalink":"/article/fZhPHPy2/"},"readingTime":{"minutes":2.93,"words":878},"git":{"updatedTime":1750029278000,"changelog":[{"hash":"23359a1c22b9bf344b1a09d678a8b1f5d123f6a0","time":1750029278000,"email":"rr@jjyy.bb","author":"rr","message":"new article"}]},"filePathRelative":"Operations/fZhPHPy2.md","headers":[],"categoryList":[{"id":"456d0d","sort":10001,"name":"Operations"}]}');export{d as comp,p as data};
